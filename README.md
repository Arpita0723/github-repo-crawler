# ğŸ” GitHub Repo Crawler

A simple Streamlit-based tool that allows you to fetch and download all `.py` files from any public GitHub repository â€” directly from a user-friendly web interface!

---

## âœ¨ Features

- âœ… Enter any public GitHub repo URL
- ğŸ“ Recursively fetches all Python files in subfolders
- ğŸ’¾ Saves files locally, preserving directory structure
- ğŸŒ Clean, Streamlit-powered UI

---

## ğŸ›  Tech Stack

- Python 3.10+
- Streamlit
- GitHub REST API
- `requests`, `os`, `json`, `urllib.parse`

---

## ğŸš€ How to Run Locally

```bash
# 1. Clone the repo
git clone https://github.com/Arpita0723/github-repo-crawler.git
cd github-repo-crawler

# 2. Create virtual environment (optional but recommended)
python -m venv .venv
.\.venv\Scripts\activate        # On Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
streamlit run app.py
